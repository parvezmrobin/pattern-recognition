{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train NN by Iris Dataset using 10-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_iris()\n",
    "Features, Labels = raw_data.data, raw_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, categories='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define layer sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_size = 50\n",
    "layer_2_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define number of inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_input = Features.shape[1]\n",
    "num_output = len(np.unique(Labels, axis=0))\n",
    "\n",
    "num_input, num_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"input\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, num_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"layer_1\"):\n",
    "    weights = tf.get_variable(\n",
    "        \"weights1\", \n",
    "        shape=[num_input, layer_1_size],\n",
    "        initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(\n",
    "        \"bias1\",\n",
    "        shape=[layer_1_size],\n",
    "        initializer=tf.zeros_initializer()\n",
    "    )\n",
    "    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"layer_2\"):\n",
    "    weights = tf.get_variable(\n",
    "        \"weights2\", \n",
    "        shape=[layer_1_size, layer_2_size],\n",
    "        initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(\n",
    "        \"bias2\",\n",
    "        shape=[layer_2_size],\n",
    "        initializer=tf.zeros_initializer()\n",
    "    )\n",
    "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"output\"):\n",
    "    weights = tf.get_variable(\n",
    "        \"weights3\", \n",
    "        shape=[layer_2_size, num_output],\n",
    "        initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(\n",
    "        \"bias3\",\n",
    "        shape=[num_output],\n",
    "        initializer=tf.zeros_initializer()\n",
    "    )\n",
    "    prediction = tf.matmul(layer_2_output, weights) + biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"cost\"):\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, num_output])\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"accuracy\"):\n",
    "    corr_pred = tf.equal(tf.argmax(Y, axis=1), tf.argmax(prediction, axis=1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(corr_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"logging\"):\n",
    "    tf.summary.scalar(\"current_cost\", cost)\n",
    "    tf.summary.scalar(\"current_accuracy\", accuracy)\n",
    "    summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare utility variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer = tf.summary.FileWriter('assignments/neural-network/tmp/train')\n",
    "test_writer = tf.summary.FileWriter('assignments/neural-network/tmp/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress():\n",
    "    train_cost, train_summary = session.run(\n",
    "        [cost, summary], feed_dict=train_feed\n",
    "    )\n",
    "    test_cost, test_summary = session.run(\n",
    "        [cost, summary], feed_dict=test_feed\n",
    "    )\n",
    "    train_acc = session.run(accuracy, feed_dict=train_feed)\n",
    "    test_acc = session.run(accuracy, feed_dict=test_feed)\n",
    "    print(epoch, train_cost, test_cost, train_acc, test_acc)\n",
    "    train_writer.add_summary(train_summary, epoch)\n",
    "    test_writer.add_summary(test_summary, epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_feed_dict, test_feed_dict, log=False):\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(training_epochs):\n",
    "            session.run(optimizer, feed_dict=train_feed)\n",
    "    \n",
    "            if epoch % 1000 == 0 and log:\n",
    "                log_progress()\n",
    "    \n",
    "        if log:\n",
    "            print(\"Training is completed\", \"\\n\")\n",
    "        final_train_acc = session.run(accuracy, feed_dict=train_feed_dict)\n",
    "        final_test_acc = session.run(accuracy, feed_dict=test_feed_dict)\n",
    "        \n",
    "        if log:\n",
    "            print(\"Final Train Accuracy:\", final_train_acc)\n",
    "            print(\"Final Test Accuracy:\", final_test_acc)\n",
    "            print(\"--------------------------------------\")\n",
    "        \n",
    "        return final_train_acc, final_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(features, labels, train_index, test_index):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    Y_train, Y_test = labels[train_index], labels[test_index]\n",
    "    X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "    X_test_scaled = X_scaler.fit_transform(X_test)\n",
    "    Y_train_encoded = one_hot_encoder.fit_transform(Y_train.reshape((-1, 1)))\n",
    "    Y_test_encoded = one_hot_encoder.fit_transform(Y_test.reshape((-1, 1)))\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, Y_train_encoded, Y_test_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9851852\n",
      "Test accuracy: 1.0\n",
      "\n",
      "Train accuracy: 0.9851852\n",
      "Test accuracy: 0.8\n",
      "\n",
      "Train accuracy: 1.0\n",
      "Test accuracy: 0.8\n",
      "\n",
      "Train accuracy: 0.9777778\n",
      "Test accuracy: 1.0\n",
      "\n",
      "Train accuracy: 0.9851852\n",
      "Test accuracy: 0.93333334\n",
      "\n",
      "Train accuracy: 0.9851852\n",
      "Test accuracy: 0.93333334\n",
      "\n",
      "Train accuracy: 0.9851852\n",
      "Test accuracy: 1.0\n",
      "\n",
      "Train accuracy: 0.9851852\n",
      "Test accuracy: 0.8666667\n",
      "\n",
      "Train accuracy: 0.9777778\n",
      "Test accuracy: 1.0\n",
      "\n",
      "Train accuracy: 0.9851852\n",
      "Test accuracy: 1.0\n",
      "\n",
      "\n",
      "Final train accuracy: 0.9851851999759674\n",
      "Final test accuracy: 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, test_accuracy = 0, 0\n",
    "\n",
    "for train_index, test_index in skf.split(Features, Labels):\n",
    "    X_train_scaled, X_test_scaled, Y_train_encoded, Y_test_encoded = pre_process(\n",
    "        Features, Labels, train_index, test_index\n",
    "    ) \n",
    "        \n",
    "    train_feed = {X: X_train_scaled, Y: Y_train_encoded}\n",
    "    test_feed = {X: X_test_scaled, Y: Y_test_encoded}\n",
    "    \n",
    "    train_acc, test_acc = run_training(train_feed, test_feed)\n",
    "    train_accuracy += train_acc\n",
    "    test_accuracy += test_acc\n",
    "    \n",
    "    print(\"Train accuracy:\", train_acc)\n",
    "    print(\"Test accuracy:\", test_acc)\n",
    "    print(\"\")\n",
    "    \n",
    "train_accuracy /= 10\n",
    "test_accuracy /= 10\n",
    "\n",
    "train_writer.close()\n",
    "test_writer.close()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Final train accuracy:\", train_accuracy)\n",
    "print(\"Final test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
